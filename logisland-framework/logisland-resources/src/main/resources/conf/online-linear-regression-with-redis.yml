#########################################################################################################
# Logisland configuration script template
#########################################################################################################

version: 0.13.0
documentation: LogIsland analytics main config file. Put here every engine or component config

#########################################################################################################
# engine
engine:
  component: com.hurence.logisland.engine.spark.KafkaStreamProcessingEngine
  type: engine
  documentation: A logisland stream that match custom queries
  configuration:
    spark.app.name: QueryMatchingDemo
    spark.master: local[2]
    spark.driver.memory: 1g
    spark.driver.cores: 1
    spark.executor.memory: 2g
    spark.executor.instances: 4
    spark.executor.cores: 2
    spark.yarn.queue: default
    spark.yarn.maxAppAttempts: 4
    spark.yarn.am.attemptFailuresValidityInterval: 1h
    spark.yarn.max.executor.failures: 20
    spark.yarn.executor.failuresValidityInterval: 1h
    spark.task.maxFailures: 8
    spark.serializer: org.apache.spark.serializer.KryoSerializer
    spark.streaming.batchDuration: 2000
    spark.streaming.backpressure.enabled: false
    spark.streaming.unpersist: false
    spark.streaming.blockInterval: 500
    spark.streaming.kafka.maxRatePerPartition: 3000
    spark.streaming.timeout: -1
    spark.streaming.unpersist: false
    spark.streaming.kafka.maxRetries: 3
    spark.streaming.ui.retainedBatches: 200
    spark.streaming.receiver.writeAheadLog.enable: false
    spark.ui.port: 4050

  controllerServiceConfigurations:

    - controllerService: cache_service
      component: com.hurence.logisland.redis.service.RedisKeyValueCacheService
      type: service
      documentation: redis datastore service
      configuration:
        connection.string: cosvgre75:6379
        redis.mode: standalone
        database.index: 0
        communication.timeout: 10 seconds
        pool.max.total: 8
        pool.max.idle: 8
        pool.min.idle: 0
        pool.block.when.exhausted: true
        pool.max.wait.time: 10 seconds
        pool.min.evictable.idle.time: 60 seconds
        pool.time.between.eviction.runs: 30 seconds
        pool.num.tests.per.eviction.run: -1
        pool.test.on.create: false
        pool.test.on.borrow: false
        pool.test.on.return: false
        pool.test.while.idle: true
        record.recordSerializer: com.hurence.logisland.serializer.JsonSerializer
        record.recordLightSerializer: com.hurence.logisland.serializer.JsonLightSerializer


  streamConfigurations:

    # structure metric measurements log
    - stream: parsing_stream
      component: com.hurence.logisland.stream.spark.KafkaRecordStreamParallelProcessing
      type: stream
      documentation: a processor that converts raw metric measurements logs into structured log records
      configuration:
        kafka.input.topics: logisland_raw_ali5
        kafka.output.topics: logisland_events2
        kafka.error.topics: logisland_errors
        kafka.input.topics.serializer: none
        kafka.output.topics.serializer: com.hurence.logisland.serializer.JsonSerializer
        kafka.error.topics.serializer: com.hurence.logisland.serializer.JsonSerializer
        kafka.metadata.broker.list: cosvgre75:9092
        kafka.zookeeper.quorum: cosvgre75:2181
        kafka.topic.autoCreate: true
        kafka.topic.default.partitions: 4
        kafka.topic.default.replicationFactor: 1

      processorConfigurations:

        # parse metric measurement logs
        - processor: metric_measurements_parser
          component: com.hurence.logisland.processor.SplitText
          type: parser
          documentation: a parser that produce events from ServiceNav metric_measurments
          configuration:
            record.type: sn_metric_measurements
            key.regex: \"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\”?
            value.regex: \"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\"?,\"?([^\"|^,]*)\”?
            value.fields: groupId,metricId,bucket,metricName,metricUnit,timestamp,value,critThreshold,warnThreshold,min,max,normalCheckWindow

        # convert fileds to a given type
        - processor: field_types_converter
          component: com.hurence.logisland.processor.ConvertFieldsType
          type: processor
          documentation: convert some field to a given type
          configuration:
            timestamp: long
            value: float
            normalCheckWindow: long

        # all the parsed records are added to datastore by bulk
        - processor: datastore_publisher
          component: com.hurence.logisland.processor.datastore.BulkPut
          type: processor
          documentation: "indexes processed events in datastore"
          configuration:
            datastore.client.service: cache_service


    # metric prediction
    - stream: metric_prediction
      component: com.hurence.logisland.stream.spark.KafkaRecordStreamParallelProcessing
      type: stream
      documentation: A processor that perform predcition on record list of metric measurements
      configuration:
        kafka.input.topics: logisland_events2
        kafka.output.topics: logisland_predictions
        kafka.error.topics: logisland_errors
        kafka.input.topics.serializer: com.hurence.logisland.serializer.JsonSerializer
        kafka.output.topics.serializer: com.hurence.logisland.serializer.JsonSerializer
        kafka.error.topics.serializer: com.hurence.logisland.serializer.JsonSerializer
        kafka.metadata.broker.list: cosvgre75:9092
        kafka.zookeeper.quorum: cosvgre75:2181
        kafka.topic.autoCreate: true
        kafka.topic.default.partitions: 2
        kafka.topic.default.replicationFactor: 1
      processorConfigurations:
        - processor: metric_prediction
          component: com.hurence.logisland.processor.OnlineLinearRegression
          type: processor
          documentation: Perform training and prediction on list of records
          configuration:
            cache.client.service: cache_service
            record.type: metric_predcition
            training.history.size: 60:3,300:3,1500:3,3600:3,4500:3 # normalCheckWindow:number of points
            training.timelapse: 60:300,300:300,1500:1500,3600:3600,4500:4500 # normalCheckWindow:number of seconds
            prediction.horizon.size: 60:54000,300:54000,1500:54000,3600:54000,4500:54000 # normalCheckWindow:number of seconds

    # Status evaluation system
    - stream: status_prediction
      component: com.hurence.logisland.stream.spark.KafkaRecordStreamParallelProcessing
      type: stream
      documentation: A processor that perform predcition on record list of metric measurements
      configuration:
        kafka.input.topics: logisland_predictions
        kafka.output.topics: logisland_status_predictions
        kafka.error.topics: logisland_errors
        kafka.input.topics.serializer: com.hurence.logisland.serializer.JsonSerializer
        kafka.output.topics.serializer: com.hurence.logisland.serializer.JsonSerializer
        kafka.error.topics.serializer: com.hurence.logisland.serializer.JsonSerializer
        kafka.metadata.broker.list: cosvgre75:9092
        kafka.zookeeper.quorum: cosvgre75:2181
        kafka.topic.autoCreate: true
        kafka.topic.default.partitions: 2
        kafka.topic.default.replicationFactor: 1
      processorConfigurations:
        - processor: status_evaluation
          component: com.hurence.logisland.processor.alerting.StatusEvaluationSystem
          type: processor
          documentation: Perform Status Evaluation on prediction on list of records for a given CI (GroupId)
          configuration:
            datastore.client.service: cache_service
            cache.client.service: cache_service
            js.cache.service: cache_service
            output.record.type: status_evaluation
            max.cpu.time: 100
            max.memory: 51200
            allow.no.brace: false
            max.prepared.statements: 30
